{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlalka00pq\u001b[0m (\u001b[33mlalka00pq-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt'...\n",
      "New https://pypi.org/project/ultralytics/8.3.81 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.69 üöÄ Python-3.12.1 torch-2.6.0+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov10n.pt, data=data.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\User\\Desktop\\ML_projects\\My_repo\\runs\\detect\\train7\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    863668  ultralytics.nn.modules.head.v10Detect        [6, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2,709,380 parameters, 2,709,364 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_1116.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0002605]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_1117.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0020833]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_1119.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0007813]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_1120.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0007813]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_1134.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0023438]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_1258.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0013021]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\a_350.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.000463]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train\\c_148.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0027778]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_313.jpg: ignoring corrupt image/label: negative label values [-0.00925926]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_360.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0027778]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_366.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0166667 1.0013889]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_422.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0013889]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_423.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0018518]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_424.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0018518]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_425.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0009259]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_426.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.000463]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_435.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0027778]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test\\d_436.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0143518]\n",
      "Plotting labels to c:\\Users\\User\\Desktop\\ML_projects\\My_repo\\runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\My_repo\\runs\\detect\\train7\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/5.59M [00:00<?, ?B/s]\n",
      "  2%|‚ñè         | 128k/5.59M [00:00<00:16, 346kB/s]\n",
      "  4%|‚ñç         | 256k/5.59M [00:00<00:09, 588kB/s]\n",
      "  7%|‚ñã         | 384k/5.59M [00:00<00:08, 625kB/s]\n",
      "  9%|‚ñâ         | 512k/5.59M [00:00<00:06, 768kB/s]\n",
      " 11%|‚ñà         | 640k/5.59M [00:00<00:06, 750kB/s]\n",
      " 13%|‚ñà‚ñé        | 768k/5.59M [00:01<00:07, 685kB/s]\n",
      " 16%|‚ñà‚ñå        | 896k/5.59M [00:01<00:06, 735kB/s]\n",
      " 18%|‚ñà‚ñä        | 1.00M/5.59M [00:01<00:07, 612kB/s]\n",
      " 20%|‚ñà‚ñà        | 1.12M/5.59M [00:01<00:08, 560kB/s]\n",
      " 22%|‚ñà‚ñà‚ñè       | 1.25M/5.59M [00:02<00:08, 532kB/s]\n",
      " 25%|‚ñà‚ñà‚ñç       | 1.38M/5.59M [00:02<00:08, 500kB/s]\n",
      " 27%|‚ñà‚ñà‚ñã       | 1.50M/5.59M [00:02<00:08, 500kB/s]\n",
      " 29%|‚ñà‚ñà‚ñâ       | 1.62M/5.59M [00:03<00:08, 483kB/s]\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 1.75M/5.59M [00:03<00:10, 383kB/s]\n",
      " 34%|‚ñà‚ñà‚ñà‚ñé      | 1.88M/5.59M [00:04<00:18, 208kB/s]\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 2.00M/5.59M [00:05<00:17, 219kB/s]\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 2.12M/5.59M [00:05<00:13, 260kB/s]\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 2.25M/5.59M [00:05<00:11, 304kB/s]\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2.38M/5.59M [00:06<00:10, 321kB/s]\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2.50M/5.59M [00:06<00:10, 321kB/s]\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2.62M/5.59M [00:07<00:10, 300kB/s]\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2.75M/5.59M [00:07<00:10, 271kB/s]\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2.88M/5.59M [00:08<00:11, 254kB/s]\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3.00M/5.59M [00:08<00:10, 260kB/s]\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3.12M/5.59M [00:09<00:10, 245kB/s]\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3.25M/5.59M [00:09<00:09, 252kB/s]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3.38M/5.59M [00:10<00:09, 245kB/s]\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3.50M/5.59M [00:11<00:08, 245kB/s]\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3.62M/5.59M [00:11<00:09, 214kB/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3.75M/5.59M [00:12<00:09, 197kB/s]\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3.88M/5.59M [00:13<00:10, 172kB/s]\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4.00M/5.59M [00:14<00:11, 143kB/s]\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4.12M/5.59M [00:15<00:10, 143kB/s]\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4.25M/5.59M [00:16<00:09, 141kB/s]\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4.38M/5.59M [00:17<00:08, 152kB/s]\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4.50M/5.59M [00:18<00:07, 162kB/s]\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4.62M/5.59M [00:18<00:06, 164kB/s]\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4.75M/5.59M [00:19<00:05, 169kB/s]\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4.88M/5.59M [00:20<00:04, 171kB/s]\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5.00M/5.59M [00:21<00:03, 169kB/s]\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5.12M/5.59M [00:22<00:02, 163kB/s]\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5.25M/5.59M [00:22<00:02, 160kB/s]\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5.38M/5.59M [00:23<00:01, 167kB/s]\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5.50M/5.59M [00:24<00:00, 170kB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.59M/5.59M [00:24<00:00, 178kB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.59M/5.59M [00:24<00:00, 236kB/s]\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train.cache... 904 images, 39 backgrounds, 8 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 904/904 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\train.cache... 904 images, 39 backgrounds, 8 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 904/904 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test.cache... 110 images, 0 backgrounds, 10 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110/110 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\Data_for_detectors\\test.cache... 110 images, 0 backgrounds, 10 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110/110 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "       1/10         0G      5.445      9.405      2.682        792        640:   0%|          | 0/28 [00:12<?, ?it/s]\n",
      "       1/10         0G      5.445      9.405      2.682        792        640:   4%|‚ñé         | 1/28 [00:12<05:42, 12.69s/it]\n",
      "       1/10         0G      5.667      9.529      2.707        776        640:   4%|‚ñé         | 1/28 [00:26<05:42, 12.69s/it]\n",
      "       1/10         0G      5.667      9.529      2.707        776        640:   7%|‚ñã         | 2/28 [00:26<05:40, 13.11s/it]\n",
      "       1/10         0G      5.642      9.432      2.708        941        640:   7%|‚ñã         | 2/28 [00:41<05:40, 13.11s/it]\n",
      "       1/10         0G      5.642      9.432      2.708        941        640:  11%|‚ñà         | 3/28 [00:41<05:56, 14.27s/it]\n",
      "       1/10         0G      5.583      9.367       2.69        833        640:  11%|‚ñà         | 3/28 [00:55<05:56, 14.27s/it]\n",
      "       1/10         0G      5.583      9.367       2.69        833        640:  14%|‚ñà‚ñç        | 4/28 [00:55<05:41, 14.22s/it]\n",
      "       1/10         0G      5.564      9.282      2.667        839        640:  14%|‚ñà‚ñç        | 4/28 [01:09<05:41, 14.22s/it]\n",
      "       1/10         0G      5.564      9.282      2.667        839        640:  18%|‚ñà‚ñä        | 5/28 [01:09<05:18, 13.86s/it]\n",
      "       1/10         0G      5.523      9.203      2.631        743        640:  18%|‚ñà‚ñä        | 5/28 [01:23<05:18, 13.86s/it]\n",
      "       1/10         0G      5.523      9.203      2.631        743        640:  21%|‚ñà‚ñà‚ñè       | 6/28 [01:23<05:08, 14.02s/it]\n",
      "       1/10         0G      5.506      9.111      2.594        729        640:  21%|‚ñà‚ñà‚ñè       | 6/28 [01:37<05:08, 14.02s/it]\n",
      "       1/10         0G      5.506      9.111      2.594        729        640:  25%|‚ñà‚ñà‚ñå       | 7/28 [01:37<04:52, 13.94s/it]\n",
      "       1/10         0G      5.465      9.013      2.555        866        640:  25%|‚ñà‚ñà‚ñå       | 7/28 [01:51<04:52, 13.94s/it]\n",
      "       1/10         0G      5.465      9.013      2.555        866        640:  29%|‚ñà‚ñà‚ñä       | 8/28 [01:51<04:38, 13.92s/it]\n",
      "       1/10         0G      5.465      9.013      2.555        866        640:  29%|‚ñà‚ñà‚ñä       | 8/28 [01:51<04:39, 13.99s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Scripts\\yolo.exe\\__main__.py\", line 8, in <module>\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 986, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 806, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 207, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 362, in _do_train\n",
      "    for i, batch in pbar:\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\data\\build.py\", line 48, in __iter__\n",
      "    yield next(self.iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 764, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 288, in __getitem__\n",
      "    return self.transforms(self.get_image_and_label(index))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 294, in get_image_and_label\n",
      "    label[\"img\"], label[\"ori_shape\"], label[\"resized_shape\"] = self.load_image(index)\n",
      "                                                               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 163, in load_image\n",
      "    im = cv2.imread(f)  # BGR\n",
      "         ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\utils\\patches.py\", line 26, in imread\n",
      "    return cv2.imdecode(np.fromfile(filename, np.uint8), flags)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\ML_projects\\\\My_repo\\\\Data_for_detectors\\\\train\\\\a_365.jpg'\n"
     ]
    }
   ],
   "source": [
    "#wandb.init(project='yolo', entity='ultralytics', config={'learning_rate': 0.01,'epochs': 10, 'batch_size': 32, 'workers': 4, 'img_size': 640})\n",
    "!yolo train model='yolov10n.pt' data=data.yaml epochs=10 batch=32  workers=4\n",
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_detector(model_name, train_loader):\n",
    "    wandb.init(\n",
    "        project=f\"{model_name}_project\",\n",
    "        name=model_name,\n",
    "        config={\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"epochs\": 6,\n",
    "            \"batch_size\": 32,\n",
    "        },\n",
    "    )\n",
    "    model = YOLO(model_name)\n",
    "    model.train(data=train_loader, epochs=6)\n",
    "    wandb.log({\"model\": model_name, \"epochs\": 6})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.81 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.69  Python-3.12.1 torch-2.6.0+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=6, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train17\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'data.yaml' error  \nDataset 'data.yaml' images not found , missing path 'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\datasets\\Data_for_detectors\\test'\nNote dataset download directory is 'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\datasets'. You can update this in 'C:\\Users\\User\\AppData\\Roaming\\Ultralytics\\settings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:562\u001b[39m, in \u001b[36mBaseTrainer.get_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.data.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33myaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myml\u001b[39m\u001b[33m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.task \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdetect\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msegment\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    560\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mobb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    561\u001b[39m }:\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m     data = \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33myaml_file\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\data\\utils.py:376\u001b[39m, in \u001b[36mcheck_det_dataset\u001b[39m\u001b[34m(dataset, autodownload)\u001b[39m\n\u001b[32m    375\u001b[39m     m += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote dataset download directory is \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. You can update this in \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSETTINGS_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(m)\n\u001b[32m    377\u001b[39m t = time.time()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: \nDataset 'data.yaml' images not found ‚ö†Ô∏è, missing path 'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\datasets\\Data_for_detectors\\test'\nNote dataset download directory is 'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\datasets'. You can update this in 'C:\\Users\\User\\AppData\\Roaming\\Ultralytics\\settings.json'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m train_loader = \u001b[33m'\u001b[39m\u001b[33mdata.yaml\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolov8s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_detector\u001b[39m\u001b[34m(model_name, train_loader)\u001b[39m\n\u001b[32m      2\u001b[39m wandb.init(\n\u001b[32m      3\u001b[39m     project=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_project\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     name=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     },\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m model = YOLO(model_name)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m wandb.log({\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model_name, \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m6\u001b[39m})\n\u001b[32m     14\u001b[39m wandb.finish()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    798\u001b[39m     args[\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.ckpt_path\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer = \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:133\u001b[39m, in \u001b[36mBaseTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28mself\u001b[39m.model = check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m.args.model)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainset, \u001b[38;5;28mself\u001b[39m.testset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m.ema = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\ML_projects\\My_repo\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:566\u001b[39m, in \u001b[36mBaseTrainer.get_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m             \u001b[38;5;28mself\u001b[39m.args.data = data[\u001b[33m\"\u001b[39m\u001b[33myaml_file\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m.args.data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m error ‚ùå \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m], data.get(\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Dataset 'data.yaml' error  \nDataset 'data.yaml' images not found , missing path 'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\datasets\\Data_for_detectors\\test'\nNote dataset download directory is 'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\datasets'. You can update this in 'C:\\Users\\User\\AppData\\Roaming\\Ultralytics\\settings.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = 'data.yaml'\n",
    "\n",
    "train_detector(model_name='yolov8s', train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n",
    "data_folder = 'Data_for_detectors'\n",
    "\n",
    "# –ü–∞–ø–∫–∏ –¥–ª—è train, test –∏ validation –≤—ã–±–æ—Ä–æ–∫\n",
    "train_folder = os.path.join(data_folder, 'train')\n",
    "test_folder = os.path.join(data_folder, 'test')\n",
    "val_folder = os.path.join(data_folder, 'val')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤\n",
    "def move_files(file_list, destination_folder):\n",
    "    with open(file_list, 'r') as f:\n",
    "        files = f.read().splitlines()\n",
    "        for file in files:\n",
    "            src = os.path.join(data_folder, file)\n",
    "            dst = os.path.join(destination_folder, file)\n",
    "            if os.path.exists(src):\n",
    "                shutil.move(src, dst)\n",
    "\n",
    "\n",
    "# –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞–ø–∫–∏\n",
    "move_files(r'Data_for_detectors\\train.txt', train_folder)\n",
    "move_files(r'Data_for_detectors\\test.txt', test_folder)\n",
    "move_files(r'Data_for_detectors\\validation.txt', val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
